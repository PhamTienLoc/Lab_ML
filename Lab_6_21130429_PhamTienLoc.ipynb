{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhamTienLoc/Lab_ML/blob/main/Lab_6_21130429_PhamTienLoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**.\n",
        "\n",
        "*   **Deadline: 23:59, 15/04/2024**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qAxSgpZOCN6",
        "outputId": "bf97c851-5b9d-404c-ecf1-5ff33c101f71"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1.\n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **FASHION** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data1 = pd.read_csv('fashion_train.csv')\n",
        "data2 = pd.read_csv('fashion_test.csv')\n",
        "X_train = data1.drop(columns='y')\n",
        "y_train = data1[['y']]\n",
        "X_test = data2.drop(columns='y')\n",
        "y_test = data2[['y']]\n",
        "\n",
        "\n",
        "print(\"Without using selection feature\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = ComplementNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes ComplementNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "\n",
        "print(\"---------<!>-----------\")\n",
        "print(\"Using selection feature\")\n",
        "X_new = SelectKBest(chi2, k = 500).fit_transform(X_train, y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_train, test_size=0.3)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = ComplementNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes ComplementNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ed40ac-9f5f-4bfe-a9dc-c3f15c5601b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature\n",
            "Random forest\n",
            "Accuracy: 0.809\n",
            "Precision: 0.8053129864962015\n",
            "Recall: 0.805652488499241\n",
            "F1 measure: 0.8009774045667546\n",
            "--------------------------\n",
            "Naive Bayes ComplementNB\n",
            "Accuracy: 0.624\n",
            "Precision: 0.7117262920779821\n",
            "Recall: 0.6273616396626013\n",
            "F1 measure: 0.5502998192559307\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.809\n",
            "Precision: 0.8117729613602249\n",
            "Recall: 0.8080638899207333\n",
            "F1 measure: 0.8054464844513045\n",
            "---------<!>-----------\n",
            "Using selection feature\n",
            "Random forest\n",
            "Accuracy: 0.81\n",
            "Precision: 0.8050017023140988\n",
            "Recall: 0.8215246495108623\n",
            "F1 measure: 0.8094059149614944\n",
            "--------------------------\n",
            "Naive Bayes ComplementNB\n",
            "Accuracy: 0.53\n",
            "Precision: 0.6968755582866972\n",
            "Recall: 0.5541390719032544\n",
            "F1 measure: 0.4486962220415725\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.78\n",
            "Precision: 0.7865095675139228\n",
            "Recall: 0.7868606211812114\n",
            "F1 measure: 0.7808266994663084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2.\n",
        "For given bank dataset (**bank.csv**) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "data3 = pd.read_csv('bank.csv')\n",
        "columns = ['age','balance','day','campaign','pdays','previous']\n",
        "scaler = StandardScaler()\n",
        "for i in columns:\n",
        "  data3[[i]] = scaler.fit_transform(data3[[i]])\n",
        "  data3[[i]] += abs(data3[[i]].min())"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "le = LabelEncoder()\n",
        "columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for i in columns:\n",
        "  data3[i] = le.fit_transform(data3[i])"
      ],
      "metadata": {
        "id": "egtgBmAtd0um"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3. Apply **Decision tree, Logistic Regression, Random forest, kNN, Na√ØveBayes, SVM** algorithms to the preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "X = data3.drop(columns='deposit')\n",
        "y = data3[['deposit']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
        "\n",
        "print(\"Without using selection feature\")\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_dt, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "lr_classifier = LogisticRegression(max_iter = 1000)\n",
        "lr_classifier.fit(X_train, y_train.values.ravel())\n",
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_lr, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "kNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN_classifier.fit(X_train,y_train.values.ravel())\n",
        "y_pred_kNN = kNN_classifier.predict(X_test)\n",
        "print(\"kNN\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_kNN))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_kNN, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes GaussianNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cac979b-5d98-4056-bfdd-1aa53d1abf68"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature\n",
            "Decision Tree\n",
            "Accuracy: 0.7868020304568528\n",
            "Precision: 0.7865414146197949\n",
            "Recall: 0.7855721508667544\n",
            "F1 measure: 0.7859197162005075\n",
            "--------------------------\n",
            "Logistic Regression\n",
            "Accuracy: 0.7981487011048074\n",
            "Precision: 0.7979086866078473\n",
            "Recall: 0.7970096258367183\n",
            "F1 measure: 0.7973442613559055\n",
            "--------------------------\n",
            "Random forest\n",
            "Accuracy: 0.8447297700806211\n",
            "Precision: 0.8452202587855231\n",
            "Recall: 0.8460359574346359\n",
            "F1 measure: 0.8446815645646932\n",
            "--------------------------\n",
            "kNN\n",
            "Accuracy: 0.7339504329650642\n",
            "Precision: 0.7334518588755876\n",
            "Recall: 0.7324142542479546\n",
            "F1 measure: 0.7327333185546441\n",
            "--------------------------\n",
            "Naive Bayes GaussianNB\n",
            "Accuracy: 0.7476858763810093\n",
            "Precision: 0.7564661384858623\n",
            "Recall: 0.7519637851135649\n",
            "F1 measure: 0.7471650487813617\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.7990444908928038\n",
            "Precision: 0.7985039949424778\n",
            "Recall: 0.7988402154013388\n",
            "F1 measure: 0.798640544018248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.4. Using a selection feature technique to above dataset, then compare the classification results with those in Task 2.3."
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(\"Using selection feature\")\n",
        "X_new = SelectKBest(chi2, k = 10).fit_transform(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_dt, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "kNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN_classifier.fit(X_train,y_train.values.ravel())\n",
        "y_pred_kNN = kNN_classifier.predict(X_test)\n",
        "print(\"kNN\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_kNN))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_kNN, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "lr_classifier = LogisticRegression(max_iter = 1000)\n",
        "lr_classifier.fit(X_train, y_train.values.ravel())\n",
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_lr, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = ComplementNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes ComplementNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd112c0-d560-435c-8361-9e01cb2c8ead"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "Decision Tree\n",
            "Accuracy: 0.7299596954769368\n",
            "Precision: 0.7284733297891193\n",
            "Recall: 0.7288471654757986\n",
            "F1 measure: 0.7286352772789264\n",
            "--------------------------\n",
            "kNN\n",
            "Accuracy: 0.7402597402597403\n",
            "Precision: 0.7395944516582589\n",
            "Recall: 0.740876869404695\n",
            "F1 measure: 0.7396619790787241\n",
            "--------------------------\n",
            "Logistic Regression\n",
            "Accuracy: 0.7886251679355127\n",
            "Precision: 0.7875487677844706\n",
            "Recall: 0.7868620464858096\n",
            "F1 measure: 0.787164301592225\n",
            "--------------------------\n",
            "Random forest\n",
            "Accuracy: 0.7845947156291984\n",
            "Precision: 0.7836109210192351\n",
            "Recall: 0.7848877550361779\n",
            "F1 measure: 0.78392842522088\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.7877295118674429\n",
            "Precision: 0.7873418665999152\n",
            "Recall: 0.7889609918091514\n",
            "F1 measure: 0.7873282056227998\n",
            "--------------------------\n",
            "Naive Bayes ComplementNB\n",
            "Accuracy: 0.7245857590685177\n",
            "Precision: 0.7235673656854252\n",
            "Recall: 0.7207152147112548\n",
            "F1 measure: 0.7214746786035676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3.\n",
        "For a given dataset (**mobile price classification**), perform feature selection techniques and then compare the performance of selected classification algorithms (**Decision Tree, kNN, Logistic Regression, SVM, Random Forest, and NaiveBayes**) based on **accuracy, precision, recall, and f1** measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data4 = pd.read_csv('mobile.csv')\n",
        "X = data4.drop(columns='price_range')\n",
        "y = data4[['price_range']]\n",
        "\n",
        "print(\"Using selection feature\")\n",
        "X_new = SelectKBest(chi2, k = 10).fit_transform(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_dt, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "kNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN_classifier.fit(X_train,y_train.values.ravel())\n",
        "y_pred_kNN = kNN_classifier.predict(X_test)\n",
        "print(\"kNN\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_kNN))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_kNN, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "lr_classifier = LogisticRegression(max_iter = 1000)\n",
        "lr_classifier.fit(X_train, y_train.values.ravel())\n",
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_lr, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = ComplementNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes ComplementNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5570d6a6-c99c-491e-8db3-112b5bd964e9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "Decision Tree\n",
            "Accuracy: 0.8475\n",
            "Precision: 0.8433503512256891\n",
            "Recall: 0.8437324659432236\n",
            "F1 measure: 0.8430601345171398\n",
            "--------------------------\n",
            "kNN\n",
            "Accuracy: 0.93\n",
            "Precision: 0.9265841754989267\n",
            "Recall: 0.9260746973573762\n",
            "F1 measure: 0.9262385837808086\n",
            "--------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.735\n",
            "Precision: 0.7365388040635565\n",
            "Recall: 0.7270050516287584\n",
            "F1 measure: 0.7299465611143242\n",
            "--------------------------\n",
            "Random forest\n",
            "Accuracy: 0.9175\n",
            "Precision: 0.9145962732919255\n",
            "Recall: 0.914568462464224\n",
            "F1 measure: 0.9144296905756136\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.9775\n",
            "Precision: 0.9766161616161617\n",
            "Recall: 0.9768993163361279\n",
            "F1 measure: 0.9767442687527321\n",
            "--------------------------\n",
            "Naive Bayes ComplementNB\n",
            "Accuracy: 0.49\n",
            "Precision: 0.7463989578897268\n",
            "Recall: 0.46590909090909094\n",
            "F1 measure: 0.32171080218043413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.\n",
        "For a given dataset (named **mushroom.csv**) with the following information:\n",
        "\n",
        "*   Attribute Information: (**classes**: edible=e, poisonous=p)\n",
        "*   **cap-shape**: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
        "*   **cap-surface**: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "*   **cap-color**: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "*   **bruises**: bruises=t,no=f\n",
        "*   **odor**: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
        "*   **gill-attachment**: attached=a,descending=d,free=f,notched=n\n",
        "*   **gill-spacing**: close=c,crowded=w,distant=d\n",
        "*   **gill-size**: broad=b,narrow=n\n",
        "*   **gill-color**: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "*   **stalk-shape**: enlarging=e,tapering=t\n",
        "*   **stalk-root**: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n",
        "*   **stalk-surface-above-ring**: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "*   **stalk-surface-below-ring**: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "*   **stalk-color-above-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "*   **stalk-color-below-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "*   **veil-type**: partial=p,universal=u\n",
        "*   **veil-color**: brown=n,orange=o,white=w,yellow=y\n",
        "*   **ring-number**: none=n,one=o,two=t\n",
        "*   **ring-type**: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
        "*   **spore-print-color**: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
        "*   **population**: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
        "*   **habitat**: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d"
      ],
      "metadata": {
        "id": "01l4jOwqRosO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.1. Apply approriate reprocessing techniques for the mushroom dataset"
      ],
      "metadata": {
        "id": "-sdulZgrUKa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "data5 = pd.read_csv('mushrooms.csv')\n",
        "columns = data5.drop(columns='class').columns\n",
        "le = LabelEncoder()\n",
        "for i in columns:\n",
        "  data5[i] = le.fit_transform(data5[i])\n",
        "X = data5.drop(columns='class')\n",
        "y = data5[['class']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "b0EAe9xyUTdJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.2. Apply classification algorithms (**Decision Tree, Logistic Regression, SVM, kNN, Random Forest, NaiveBayes**) to the reprocessed dataset"
      ],
      "metadata": {
        "id": "TLjmCHZdUUdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(\"Without using selection feature\")\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_dt, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "lr_classifier = LogisticRegression(max_iter = 1000)\n",
        "lr_classifier.fit(X_train, y_train.values.ravel())\n",
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_lr, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "kNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN_classifier.fit(X_train,y_train.values.ravel())\n",
        "y_pred_kNN = kNN_classifier.predict(X_test)\n",
        "print(\"kNN\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_kNN))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_kNN, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes GaussianNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))"
      ],
      "metadata": {
        "id": "Z4qZBUVWUt6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a678958d-7a98-4ae4-d45a-625753c9596c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature\n",
            "Decision Tree\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 measure: 1.0\n",
            "--------------------------\n",
            "Logistic Regression\n",
            "Accuracy: 0.9491386382280558\n",
            "Precision: 0.9495847825500823\n",
            "Recall: 0.9489456622996193\n",
            "F1 measure: 0.9491013366808722\n",
            "--------------------------\n",
            "Random forest\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 measure: 1.0\n",
            "--------------------------\n",
            "kNN\n",
            "Accuracy: 0.9975389663658737\n",
            "Precision: 0.9975845410628019\n",
            "Recall: 0.997504159733777\n",
            "F1 measure: 0.9975383037115271\n",
            "--------------------------\n",
            "Naive Bayes GaussianNB\n",
            "Accuracy: 0.9200164068908941\n",
            "Precision: 0.9199887340777995\n",
            "Recall: 0.9200523399512139\n",
            "F1 measure: 0.9200079956669946\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.9622641509433962\n",
            "Precision: 0.96229716338412\n",
            "Recall: 0.96222248248604\n",
            "F1 measure: 0.9622539902434165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4.3. Apply an feature selection method to dataset obtained in Task 4.1, then apply classification algorithm to the obtained dataset. Compare the performance of classification models before and after applying the feature selection technique in term of **accuracy, precision, recall, and F1** measures"
      ],
      "metadata": {
        "id": "jOg7DfjjVZgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(\"Using selection feature\")\n",
        "X_new = SelectKBest(chi2, k = 13).fit_transform(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_dt, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "kNN_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN_classifier.fit(X_train,y_train.values.ravel())\n",
        "y_pred_kNN = kNN_classifier.predict(X_test)\n",
        "print(\"kNN\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_kNN))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_kNN, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_kNN, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "lr_classifier = LogisticRegression(max_iter = 1000)\n",
        "lr_classifier.fit(X_train, y_train.values.ravel())\n",
        "y_pred_lr = lr_classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_lr, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_lr, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random forest\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_rf, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_rf, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "linear_clf = svm.SVC(kernel='linear')\n",
        "linear_clf.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svm_linear = linear_clf.predict(X_test)\n",
        "print(\"SVM Linear\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm_linear))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_svm_linear, average='macro'))\n",
        "\n",
        "print(\"--------------------------\")\n",
        "model = ComplementNB()\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_nb = model.predict(X_test)\n",
        "print(\"Naive Bayes ComplementNB\")\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred_nb, average='macro', zero_division=1))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred_nb, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, y_pred_nb, average='macro'))"
      ],
      "metadata": {
        "id": "tSPivXdAUu0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440e6985-4694-4a92-c0c1-7669a51966d2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "Decision Tree\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 measure: 1.0\n",
            "--------------------------\n",
            "kNN\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 measure: 1.0\n",
            "--------------------------\n",
            "Logistic Regression\n",
            "Accuracy: 0.9353846153846154\n",
            "Precision: 0.9369422217333785\n",
            "Recall: 0.9341935483870968\n",
            "F1 measure: 0.935076201989208\n",
            "--------------------------\n",
            "Random forest\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 measure: 1.0\n",
            "--------------------------\n",
            "SVM Linear\n",
            "Accuracy: 0.9421538461538461\n",
            "Precision: 0.9432962172056132\n",
            "Recall: 0.9411764705882353\n",
            "F1 measure: 0.9419113173106176\n",
            "--------------------------\n",
            "Naive Bayes ComplementNB\n",
            "Accuracy: 0.7747692307692308\n",
            "Precision: 0.8021306696390293\n",
            "Recall: 0.7674573055028463\n",
            "F1 measure: 0.7659754466042339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}