{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhamTienLoc/Lab_ML/blob/main/Lab_10_21130429_PhamTienLoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **cross validation** for some classification algorithms and **clustering methods** using sklearn api.\n",
        "\n",
        "*   **Deadline: 23:59, 20/5/2024**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import set_config\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6nRvAhYbUuP",
        "outputId": "9db8ce97-e856-4c28-efec-bfecff9210ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **SVM** algorithm with cross validation\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "svm_clf =svm.SVC(kernel=\"sigmoid\", random_state=0)\n",
        "\n",
        "svm_scores = cross_validate(svm_clf, X, y, scoring='accuracy', cv=10)\n",
        "\n",
        "print(sorted(svm_scores.keys()))\n",
        "print(np.mean(svm_scores['test_score']))"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b09582-4563-455a-9784-b31992ac3ddf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fit_time', 'score_time', 'test_score']\n",
            "0.06666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2 Apply **feature selection** to the dataset and then use **RandomForest**, **kNN** algorithm with cross validation"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "X_new = SelectKBest(chi2, k = 2).fit_transform(X, y)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "rf_scores = cross_validate(rf_clf, X_new, y, scoring='accuracy', cv=10)\n",
        "\n",
        "kNN_clf = KNeighborsClassifier(n_neighbors=10)\n",
        "kNN_scores = cross_validate(kNN_clf, X_new, y, scoring='accuracy', cv=10)"
      ],
      "metadata": {
        "id": "fX0_kItYPism"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3 Compare the obtained results of these approaches (SVM, RandomForest, kNN) using PrettyTable"
      ],
      "metadata": {
        "id": "gtb8ltIqTohd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "t = PrettyTable(['Algorithms', 'Test score'])\n",
        "t.add_row(['SVM', np.mean(svm_scores['test_score'])])\n",
        "t.add_row(['Random Forest with feature selection', np.mean(rf_scores['test_score'])])\n",
        "t.add_row(['kNN with feature selection', np.mean(kNN_scores['test_score'])])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "id": "N8mWDU2YT26O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7c63c9-b393-4958-940a-376b94e0c895"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+---------------------+\n",
            "|              Algorithms              |      Test score     |\n",
            "+--------------------------------------+---------------------+\n",
            "|                 SVM                  | 0.06666666666666668 |\n",
            "| Random Forest with feature selection |  0.9666666666666666 |\n",
            "|      kNN with feature selection      |         0.96        |\n",
            "+--------------------------------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. With fashion dataset:\n",
        "*   2.1. Apply **K-Means** algorithm using k=10,"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data1 = pd.read_csv('fashion_train.csv')\n",
        "data2 = pd.read_csv('fashion_test.csv')\n",
        "X_train = data1.drop(columns='y')\n",
        "y_train = data1[['y']]\n",
        "X_test = data2.drop(columns='y')\n",
        "y_test = data2[['y']]\n",
        "\n",
        "kmeans = KMeans(n_clusters = 10, random_state = 42, n_init=\"auto\")\n",
        "kmeans.fit(X_train)\n",
        "clusters = kmeans.predict(X_test)\n",
        "kmeans.cluster_centers_.shape\n",
        "\n",
        "sse = []\n",
        "for k in range(1, 11):\n",
        "  kmeans = KMeans(n_clusters=k, random_state = 0, n_init=\"auto\")\n",
        "  kmeans.fit(X_train)\n",
        "  sse.append(kmeans.inertia_)\n",
        "\n",
        "labels = np.zeros_like(clusters)\n",
        "for i in range(10):\n",
        "  mask = (clusters == i)\n",
        "  #print(mask)\n",
        "  labels[mask] = mode(y_test[mask])[0]\n",
        "  #print(labels[mask])\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, labels))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, labels, average='macro', zero_division=\"warn\"))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, labels, average='macro'))\n",
        "print(\"F1 measure:\", metrics.f1_score(y_test, labels, average='macro'))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d6eaec-d6c5-4ce0-8321-5b03b37d77dc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.524\n",
            "Precision: 0.41967010205210287\n",
            "Recall: 0.523296973343057\n",
            "F1 measure: 0.45717987887159406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Compare the obtained result with with other classification algorithms such as **Randomforest**, **kNN**, and **SVM** in terms of accuracy, precision, recall, f1 using cross validation.\n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. From the obtained results, **which approach is better** for this problem: Supervised learning or Unsupervised learning?"
      ],
      "metadata": {
        "id": "uyey-ndXvZlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "Qzh_D-rgvbv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4. Apply **AgglomerativeClustering** algorithm to fashion dataset using the number of clusters is 10"
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "8h4qqiIBSytO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3.\n",
        "For given dataset (shopping-data.csv) including 5 attributes: **CustomerID**, **Genre**, **Age**, **Annual Income**, and **Spending Score**.\n",
        "*   3.1. Using the **scipy library** to create the dendrograms for the given dataset (remember drop categorical attributes: **CustomerID**, **Genre**)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "YYY2dLtH3P8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Apply K-Means to the preprocessed dataset with k belongs to [2,10]. Then compute SSE values and plot them to find the best value of k."
      ],
      "metadata": {
        "id": "eHlh_dWUyEMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. From the obtained dengrograms, choose an appropriate number of clusters and apply **AgglomerativeClustering** algorithm to the given dataset"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}